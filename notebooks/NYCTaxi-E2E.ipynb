{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://test-m:8786\n",
       "  <li><b>Dashboard: </b><a href='http://test-m:8787/status' target='_blank'>http://test-m:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>2</li>\n",
       "  <li><b>Cores: </b>2</li>\n",
       "  <li><b>Memory: </b>7.89 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.142.0.36:8786' processes=2 cores=2>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "import xgboost as xgb\n",
    "\n",
    "import dask\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.delayed import delayed\n",
    "from dask.distributed import Client, wait\n",
    "import dask_cudf\n",
    "\n",
    "import math\n",
    "\n",
    "# local dev\n",
    "#cluster = LocalCUDACluster()\n",
    "#client = Client(cluster)\n",
    "# in DataProc environment\n",
    "#ToDo- get hostname programmatically\n",
    "client = Client('test-m:8786')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform the ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2014-01-09 20:45:25</td>\n",
       "      <td>2014-01-09 20:52:31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-73.994770</td>\n",
       "      <td>40.736828</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.982227</td>\n",
       "      <td>40.731790</td>\n",
       "      <td>CRD</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2014-01-09 20:46:12</td>\n",
       "      <td>2014-01-09 20:55:12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-73.982392</td>\n",
       "      <td>40.773382</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.960449</td>\n",
       "      <td>40.763995</td>\n",
       "      <td>CRD</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2014-01-09 20:44:47</td>\n",
       "      <td>2014-01-09 20:59:46</td>\n",
       "      <td>2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-73.988570</td>\n",
       "      <td>40.739406</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.986626</td>\n",
       "      <td>40.765217</td>\n",
       "      <td>CRD</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2014-01-09 20:44:57</td>\n",
       "      <td>2014-01-09 20:51:40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-73.960213</td>\n",
       "      <td>40.770464</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.979863</td>\n",
       "      <td>40.777050</td>\n",
       "      <td>CRD</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2014-01-09 20:47:09</td>\n",
       "      <td>2014-01-09 20:53:32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-73.995371</td>\n",
       "      <td>40.717248</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.984367</td>\n",
       "      <td>40.720524</td>\n",
       "      <td>CRD</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vendor_id     pickup_datetime    dropoff_datetime   passenger_count  \\\n",
       "0       CMT 2014-01-09 20:45:25 2014-01-09 20:52:31                 1   \n",
       "1       CMT 2014-01-09 20:46:12 2014-01-09 20:55:12                 1   \n",
       "2       CMT 2014-01-09 20:44:47 2014-01-09 20:59:46                 2   \n",
       "3       CMT 2014-01-09 20:44:57 2014-01-09 20:51:40                 1   \n",
       "4       CMT 2014-01-09 20:47:09 2014-01-09 20:53:32                 1   \n",
       "\n",
       "    trip_distance   pickup_longitude   pickup_latitude   rate_code  \\\n",
       "0             0.7         -73.994770         40.736828           1   \n",
       "1             1.4         -73.982392         40.773382           1   \n",
       "2             2.3         -73.988570         40.739406           1   \n",
       "3             1.7         -73.960213         40.770464           1   \n",
       "4             0.9         -73.995371         40.717248           1   \n",
       "\n",
       "   store_and_fwd_flag   dropoff_longitude   dropoff_latitude  payment_type  \\\n",
       "0                   N          -73.982227          40.731790           CRD   \n",
       "1                   N          -73.960449          40.763995           CRD   \n",
       "2                   N          -73.986626          40.765217           CRD   \n",
       "3                   N          -73.979863          40.777050           CRD   \n",
       "4                   N          -73.984367          40.720524           CRD   \n",
       "\n",
       "    fare_amount   surcharge   mta_tax   tip_amount   tolls_amount  \\\n",
       "0           6.5         0.5       0.5         1.40            0.0   \n",
       "1           8.5         0.5       0.5         1.90            0.0   \n",
       "2          11.5         0.5       0.5         1.50            0.0   \n",
       "3           7.5         0.5       0.5         1.70            0.0   \n",
       "4           6.0         0.5       0.5         1.75            0.0   \n",
       "\n",
       "    total_amount  \n",
       "0           8.90  \n",
       "1          11.40  \n",
       "2          14.00  \n",
       "3          10.20  \n",
       "4           8.75  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taxi_df = dask_cudf.read_csv('/data/nyc_taxi/raw/2014/yellow_tripdata_2014-1*')\n",
    "taxi_df = dask_cudf.read_csv('/data/nyc_taxi/raw/2014/yellow_*')\n",
    "\n",
    "taxi_df.head().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165,114,361\n"
     ]
    }
   ],
   "source": [
    "def pretty(val):\n",
    "    print(\"{:,}\".format(val))\n",
    "\n",
    "pretty(len(taxi_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df, mapper):    \n",
    "    # some col-names include pre-pended space.. fix it\n",
    "    tmp = {col:col.strip().lower() for col in list(df.columns)}\n",
    "    df = df.rename(tmp)\n",
    "    \n",
    "    # drop any column without a supplied replacement\n",
    "    for col in mapper:\n",
    "        if col in mapper and mapper[col] == None and col in df.columns:\n",
    "            df = df.drop(col)\n",
    "    \n",
    "    # rename according to supplied mapping\n",
    "    df = df.rename(mapper)\n",
    "        \n",
    "    # fill all na values for non-object columns\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype != 'object':\n",
    "            df[col] = df[col].fillna(-1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop list\n",
    "col_map = dict.fromkeys([\n",
    "    'vendor_id', 'dropoff_datetime', 'payment_type', 'surcharge', 'mta_tax',\n",
    "    'tip_amount', 'tolls_amount', 'total_amount', 'store_and_fwd_flag'\n",
    "])\n",
    "\n",
    "parts = [dask.delayed(clean)(part, col_map) for part in taxi_df.to_delayed()]\n",
    "taxi_df = dask_cudf.from_delayed(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numba Kernel to calculate Haversine distance\n",
    "@cuda.jit\n",
    "def haversine_kernel(lat1, lon1, lat2, lon2, outputCol):\n",
    "    iRow = cuda.grid(1)\n",
    "    p = 0.017453292519943295 # Pi/180\n",
    "    if iRow < outputCol.size:\n",
    "        a = 0.5 - math.cos((lat2[iRow] - lat1[iRow]) * p)/2 + math.cos(lat1[iRow] * p) * \\\n",
    "            math.cos(lat2[iRow] * p) * (1 - math.cos((lon2[iRow] - lon1[iRow]) * p)) / 2                                 \n",
    "        outputCol[iRow] = 12734 * math.asin(math.sqrt(a))\n",
    "    \n",
    "def haversine_distance(gdf):\n",
    "    nRows = gdf.shape[0]\n",
    "    blockSize = 128\n",
    "    blockCount = nRows // blockSize + 1\n",
    "    lat1_arr = gdf['pickup_latitude'].to_gpu_array()\n",
    "    lon1_arr = gdf['pickup_longitude'].to_gpu_array()\n",
    "    lat2_arr = gdf['dropoff_latitude'].to_gpu_array()\n",
    "    lon2_arr = gdf['dropoff_longitude'].to_gpu_array()\n",
    "                                   \n",
    "    outputCol = cuda.device_array ( shape=(nRows), dtype=lat1_arr.dtype.name)\n",
    "    \n",
    "    haversine_kernel[(blockCount),(blockSize)](lat1_arr, lon1_arr, lat2_arr, lon2_arr, outputCol)\n",
    "    gdf.add_column(name='h_distance', data = outputCol)\n",
    "    return gdf\n",
    "\n",
    "#Numba Kernel to calculate day of the week from Date\n",
    "@cuda.jit\n",
    "def day_of_the_week_kernel(output ,year, month, day):\n",
    "    iRow = cuda.grid(1)\n",
    "    if iRow < output.size:\n",
    "        year[iRow] -= month[iRow] < 3\n",
    "        month[iRow] = (month[iRow] + 9)%12 + 1\n",
    "        output[iRow] = (year[iRow] + int(year[iRow]/4) - int(year[iRow]/100) + int(year[iRow]/400) + math.floor(2.6*month[iRow] - 0.2) + day[iRow] -1) % 7\n",
    "    \n",
    "def day_of_week(gdf):\n",
    "    nRows = gdf.shape[0]\n",
    "    blockSize = 128\n",
    "    blockCount = nRows // blockSize + 1\n",
    "    year_arr = gdf['year'].to_gpu_array()\n",
    "    month_arr = gdf['month'].to_gpu_array()\n",
    "    day_arr = gdf['day'].to_gpu_array()\n",
    "    outputCol = cuda.device_array ( shape=(nRows), dtype=day_arr.dtype.name)\n",
    "    \n",
    "    day_of_the_week_kernel[(blockCount),(blockSize)](outputCol, year_arr, month_arr, day_arr)\n",
    "    gdf.add_column(name='day_of_week', data = outputCol)\n",
    "    gdf['day_of_week'] = gdf['day_of_week'].astype('float32')\n",
    "    return gdf\n",
    "\n",
    "def add_features(df):\n",
    "    df['hour'] = df['pickup_datetime'].dt.hour\n",
    "    df['year'] = df['pickup_datetime'].dt.year\n",
    "    df['month'] = df['pickup_datetime'].dt.month\n",
    "    df['day'] = df['pickup_datetime'].dt.day\n",
    "    \n",
    "    df = df.drop('pickup_datetime')\n",
    "    \n",
    "    df = day_of_week(df)\n",
    "    df['is_weekend'] = (df['day_of_week']/4).floor()\n",
    "    df = haversine_distance(df)\n",
    "    return df\n",
    "\n",
    "parts = [dask.delayed(add_features)(part) for part in taxi_df.to_delayed()]\n",
    "taxi_df = dask_cudf.from_delayed(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>hour</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>h_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-73.994770</td>\n",
       "      <td>40.736828</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982227</td>\n",
       "      <td>40.731790</td>\n",
       "      <td>6.5</td>\n",
       "      <td>20</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.195381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-73.982392</td>\n",
       "      <td>40.773382</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.960449</td>\n",
       "      <td>40.763995</td>\n",
       "      <td>8.5</td>\n",
       "      <td>20</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.120985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-73.988570</td>\n",
       "      <td>40.739406</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.986626</td>\n",
       "      <td>40.765217</td>\n",
       "      <td>11.5</td>\n",
       "      <td>20</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.872915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-73.960213</td>\n",
       "      <td>40.770464</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.979863</td>\n",
       "      <td>40.777050</td>\n",
       "      <td>7.5</td>\n",
       "      <td>20</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.808353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-73.995371</td>\n",
       "      <td>40.717248</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.984367</td>\n",
       "      <td>40.720524</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_count  trip_distance  pickup_longitude  pickup_latitude  \\\n",
       "0                1            0.7        -73.994770        40.736828   \n",
       "1                1            1.4        -73.982392        40.773382   \n",
       "2                2            2.3        -73.988570        40.739406   \n",
       "3                1            1.7        -73.960213        40.770464   \n",
       "4                1            0.9        -73.995371        40.717248   \n",
       "\n",
       "   rate_code  dropoff_longitude  dropoff_latitude  fare_amount  hour  year  \\\n",
       "0          1         -73.982227         40.731790          6.5    20  2013   \n",
       "1          1         -73.960449         40.763995          8.5    20  2013   \n",
       "2          1         -73.986626         40.765217         11.5    20  2013   \n",
       "3          1         -73.979863         40.777050          7.5    20  2013   \n",
       "4          1         -73.984367         40.720524          6.0    20  2013   \n",
       "\n",
       "   month  day  day_of_week  is_weekend  h_distance  \n",
       "0     11    9          3.0         0.0    1.195381  \n",
       "1     11    9          3.0         0.0    2.120985  \n",
       "2     11    9          3.0         0.0    2.872915  \n",
       "3     11    9          3.0         0.0    1.808353  \n",
       "4     11    9          3.0         0.0    0.995734  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter data\n",
    "query_frags = [\n",
    "    'fare_amount > 0 and fare_amount < 500',\n",
    "    'passenger_count > 0 and passenger_count < 6',\n",
    "    'pickup_longitude > -75 and pickup_longitude < -73',\n",
    "    'dropoff_longitude > -75 and dropoff_longitude < -73',\n",
    "    'pickup_latitude > 40 and pickup_latitude < 42',\n",
    "    'dropoff_latitude > 40 and dropoff_latitude < 42'\n",
    "]\n",
    "taxi_df = taxi_df.query(' and '.join(query_frags))\n",
    "\n",
    "taxi_df.head().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: use multi-column groupby to compute a more meaningful train/test split boundary\n",
    "X_train = taxi_df.query('day < 25')\n",
    "\n",
    "# we'll predict fare_amount, get it as a separate DF\n",
    "def get_column_as_df(df, col):\n",
    "    return df[[col]]\n",
    "\n",
    "parts = [dask.delayed(get_column_as_df)(part, 'fare_amount') for part in X_train.to_delayed()]\n",
    "Y_train = dask_cudf.from_delayed(parts)\n",
    "\n",
    "# drop fare_amount from the training set\n",
    "parts = [dask.delayed(clean)(part, dict.fromkeys(['fare_amount'])) for part in X_train.to_delayed()]\n",
    "X_train = dask_cudf.from_delayed(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the XGBoost Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.75 s, sys: 40 ms, total: 4.79 s\n",
      "Wall time: 4min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import dask_xgboost as dxgb_gpu\n",
    "\n",
    "params = {\n",
    " 'learning_rate': 0.05,\n",
    "  'max_depth': 8,\n",
    "  'objective': 'reg:linear',\n",
    "  'subsample': 0.8,\n",
    "  'gamma': 1,\n",
    "  'silent': True,\n",
    "  'verbose_eval': True,\n",
    "  'tree_method':'gpu_hist',\n",
    "  'n_gpus': 1\n",
    "}\n",
    "\n",
    "bst = dxgb_gpu.train(client, params, X_train, Y_train, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create & Generate Predictions for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: use more meaningful train/test split logic\n",
    "X_test = taxi_df.query('day >= 25').repartition(npartitions=5)\n",
    "parts = [dask.delayed(get_column_as_df)(part, 'fare_amount') for part in X_test.to_delayed()]\n",
    "Y_test = dask_cudf.from_delayed(parts)\n",
    "\n",
    "parts = [dask.delayed(clean)(part, dict.fromkeys(['fare_amount'])) for part in X_test.to_delayed()]\n",
    "X_test = dask_cudf.from_delayed(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions on the test set\n",
    "Y_test['prediction'] = dxgb_gpu.predict(client, bst, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>prediction</th>\n",
       "      <th>squared_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205295</th>\n",
       "      <td>13.0</td>\n",
       "      <td>11.645109</td>\n",
       "      <td>1.835729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205431</th>\n",
       "      <td>7.5</td>\n",
       "      <td>7.328209</td>\n",
       "      <td>0.029512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205493</th>\n",
       "      <td>8.0</td>\n",
       "      <td>9.405614</td>\n",
       "      <td>1.975750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205805</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.701920</td>\n",
       "      <td>0.088852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206044</th>\n",
       "      <td>14.5</td>\n",
       "      <td>14.934761</td>\n",
       "      <td>0.189017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fare_amount  prediction  squared_error\n",
       "205295         13.0   11.645109       1.835729\n",
       "205431          7.5    7.328209       0.029512\n",
       "205493          8.0    9.405614       1.975750\n",
       "205805          8.0    7.701920       0.088852\n",
       "206044         14.5   14.934761       0.189017"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test['squared_error'] = (Y_test['prediction'] - Y_test['fare_amount'])**2\n",
    "Y_test.head().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4004054596100395"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(Y_test.squared_error.mean().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    vendor_name,Trip_Pickup_DateTime,Trip_Dropoff_...\n",
       "0    vendor_id,pickup_datetime,dropoff_datetime,pas...\n",
       "0    vendor_id, pickup_datetime, dropoff_datetime, ...\n",
       "0    VendorID,tpep_pickup_datetime,tpep_dropoff_dat...\n",
       "0    VendorID,tpep_pickup_datetime,tpep_dropoff_dat...\n",
       "0    VendorID,tpep_pickup_datetime,tpep_dropoff_dat...\n",
       "Name: line, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# generate list of all files\n",
    "base_dir = '/data/nyc_taxi/raw/'\n",
    "files = []\n",
    "for year in range(2009, 2019):\n",
    "    for fn in os.listdir(base_dir+str(year)):\n",
    "        if 'yellow' in fn:\n",
    "            files.append(base_dir+str(year)+'/'+fn)\n",
    "\n",
    "# get list of headers\n",
    "def get_columns(fn):\n",
    "    df = pd.DataFrame()\n",
    "    with open(fn, 'r') as fp:\n",
    "        df['year'] = [fn.split('-')[-2].split('_')[-1]]\n",
    "        df['month'] = [fn.split('-')[-1].split('.')[0]]\n",
    "        df['line'] = [fp.readline()]\n",
    "    return df\n",
    "\n",
    "parts = [dask.delayed(get_columns)(fn) for fn in files]\n",
    "res = dask.dataframe.from_delayed(parts)\n",
    "res.repartition(npartitions=1).compute().line.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return columns in df2 but not df1\n",
    "def column_delta(df1, df2):\n",
    "    return list(set(df2.columns.map(str.lower)) - set(df1.columns.map(str.lower)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# years >= 2015 data has different column names\n",
    "# remap to match existing schema\n",
    "newer_df = dask_cudf.read_csv('/data/nyc-taxi/2015/yellow_tripdata_2015-1*')\n",
    "\n",
    "# data for 2015+ has more columns\n",
    "# assume we should drop them\n",
    "for col in column_delta(taxi_df, newer_df):\n",
    "    col_map[col] = None\n",
    "\n",
    "#ratecodeid and tpep_pickup_datetime map to columns we had in years < 2014\n",
    "col_map['ratecodeid'] = 'rate_code'\n",
    "col_map['tpep_pickup_datetime'] = 'pickup_datetime'\n",
    "\n",
    "parts = [dask.delayed(clean_data)(part, col_map) for part in newer_df.to_delayed()]\n",
    "newer_df = dask_cudf.from_delayed(parts)\n",
    "\n",
    "taxi_df = taxi_df.append(newer_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}