{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting NYC Taxi Fares with RAPIDS\n",
    "\n",
    "[RAPIDS](https://rapids.ai/) is a suite of GPU accelerated data science libraries with APIs that should be familiar to uses of Pandas, Dask, and Scikitlearn.\n",
    "\n",
    "This notebook focuses on showing how to use cuDF with Dask & XGBoost to scale GPU DataFrame ETL-style operations & model training out to multiple GPUs on mutliple nodes as part of Google Cloud Dataproc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://test-m:8786\n",
       "  <li><b>Dashboard: </b><a href='http://test-m:8787/status' target='_blank'>http://test-m:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>13</li>\n",
       "  <li><b>Cores: </b>13</li>\n",
       "  <li><b>Memory: </b>51.27 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.142.15.211:8786' processes=13 cores=13>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numba, xgboost, socket\n",
    "\n",
    "import dask, dask_cudf\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.delayed import delayed\n",
    "from dask.distributed import Client, wait\n",
    "\n",
    "# connect to the Dask cluster started at Dataproc cluster creation time\n",
    "client = Client(socket.gethostname()+':8786')\n",
    "# forces workers to restart. useful to ensure GPU memory is clear\n",
    "client.restart()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting the Data\n",
    "\n",
    "Now that we have a cluster of GPU workers, we'll use [dask-cudf](https://github.com/rapidsai/dask-cudf/) to load and parse a bunch of CSV files into a distributed DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2011-01-29 02:38:35</td>\n",
       "      <td>2011-01-29 02:47:07</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-74.005254</td>\n",
       "      <td>40.729084</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.988697</td>\n",
       "      <td>40.727127</td>\n",
       "      <td>CSH</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2011-01-28 10:38:19</td>\n",
       "      <td>2011-01-28 10:42:18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-73.968585</td>\n",
       "      <td>40.759171</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.964336</td>\n",
       "      <td>40.764665</td>\n",
       "      <td>CSH</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2011-01-28 23:49:58</td>\n",
       "      <td>2011-01-28 23:57:44</td>\n",
       "      <td>3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-73.980710</td>\n",
       "      <td>40.742390</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.987028</td>\n",
       "      <td>40.729532</td>\n",
       "      <td>CSH</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2011-01-28 23:52:09</td>\n",
       "      <td>2011-01-28 23:59:21</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-73.993773</td>\n",
       "      <td>40.747329</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.991378</td>\n",
       "      <td>40.750050</td>\n",
       "      <td>CSH</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2011-01-28 10:34:39</td>\n",
       "      <td>2011-01-28 11:25:50</td>\n",
       "      <td>1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>-73.991475</td>\n",
       "      <td>40.749936</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.950237</td>\n",
       "      <td>40.775626</td>\n",
       "      <td>CSH</td>\n",
       "      <td>25.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vendor_id     pickup_datetime    dropoff_datetime  passenger_count  \\\n",
       "0       CMT 2011-01-29 02:38:35 2011-01-29 02:47:07                1   \n",
       "1       CMT 2011-01-28 10:38:19 2011-01-28 10:42:18                1   \n",
       "2       CMT 2011-01-28 23:49:58 2011-01-28 23:57:44                3   \n",
       "3       CMT 2011-01-28 23:52:09 2011-01-28 23:59:21                3   \n",
       "4       CMT 2011-01-28 10:34:39 2011-01-28 11:25:50                1   \n",
       "\n",
       "   trip_distance  pickup_longitude  pickup_latitude  rate_code  \\\n",
       "0            1.2        -74.005254        40.729084          1   \n",
       "1            0.4        -73.968585        40.759171          1   \n",
       "2            1.2        -73.980710        40.742390          1   \n",
       "3            0.8        -73.993773        40.747329          1   \n",
       "4            5.3        -73.991475        40.749936          1   \n",
       "\n",
       "  store_and_fwd_flag  dropoff_longitude  dropoff_latitude payment_type  \\\n",
       "0                  N         -73.988697         40.727127          CSH   \n",
       "1                  N         -73.964336         40.764665          CSH   \n",
       "2                  N         -73.987028         40.729532          CSH   \n",
       "3                  N         -73.991378         40.750050          CSH   \n",
       "4                  N         -73.950237         40.775626          CSH   \n",
       "\n",
       "   fare_amount  surcharge  mta_tax  tip_amount  tolls_amount  total_amount  \n",
       "0          6.1        0.5      0.5         0.0           0.0           7.1  \n",
       "1          4.1        0.0      0.5         0.0           0.0           4.6  \n",
       "2          6.1        0.5      0.5         0.0           0.0           7.1  \n",
       "3          5.3        0.5      0.5         0.0           0.0           6.3  \n",
       "4         25.3        0.0      0.5         0.0           0.0          25.8  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taxi_df = dask_cudf.read_csv('/data/nyc_taxi/raw/2014/yellow_tripdata_2014-1*')\n",
    "taxi_df = dask_cudf.read_csv('/data/nyc_taxi/raw/2011/yellow_tripdata_2011*')\n",
    "\n",
    "taxi_df.head().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleanup\n",
    "\n",
    "As usual, the data needs to be massaged a bit before we can start adding features that are useful to an ML model.\n",
    "\n",
    "In this case, the taxi data for different years has different column names. We'll do a little string manipulation, column renaming and dropping to fix the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29 02:38:35</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-74.005254</td>\n",
       "      <td>40.729084</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.988697</td>\n",
       "      <td>40.727127</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-28 10:38:19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-73.968585</td>\n",
       "      <td>40.759171</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.964336</td>\n",
       "      <td>40.764665</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-28 23:49:58</td>\n",
       "      <td>3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-73.980710</td>\n",
       "      <td>40.742390</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.987028</td>\n",
       "      <td>40.729532</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-28 23:52:09</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-73.993773</td>\n",
       "      <td>40.747329</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.991378</td>\n",
       "      <td>40.750050</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-28 10:34:39</td>\n",
       "      <td>1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>-73.991475</td>\n",
       "      <td>40.749936</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.950237</td>\n",
       "      <td>40.775626</td>\n",
       "      <td>25.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pickup_datetime  passenger_count  trip_distance  pickup_longitude  \\\n",
       "0 2011-01-29 02:38:35                1            1.2        -74.005254   \n",
       "1 2011-01-28 10:38:19                1            0.4        -73.968585   \n",
       "2 2011-01-28 23:49:58                3            1.2        -73.980710   \n",
       "3 2011-01-28 23:52:09                3            0.8        -73.993773   \n",
       "4 2011-01-28 10:34:39                1            5.3        -73.991475   \n",
       "\n",
       "   pickup_latitude  rate_code  dropoff_longitude  dropoff_latitude  \\\n",
       "0        40.729084          1         -73.988697         40.727127   \n",
       "1        40.759171          1         -73.964336         40.764665   \n",
       "2        40.742390          1         -73.987028         40.729532   \n",
       "3        40.747329          1         -73.991378         40.750050   \n",
       "4        40.749936          1         -73.950237         40.775626   \n",
       "\n",
       "   fare_amount  \n",
       "0          6.1  \n",
       "1          4.1  \n",
       "2          6.1  \n",
       "3          5.3  \n",
       "4         25.3  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# helper function which takes a DataFrame partition\n",
    "def clean(df_part, mapper):    \n",
    "    # some col-names include pre-pended space.. remove them\n",
    "    tmp = {col:col.strip().lower() for col in list(df_part.columns)}\n",
    "    df_part = df_part.rename(tmp)\n",
    "    \n",
    "    # drop any column without a supplied replacement name\n",
    "    for col in mapper:\n",
    "        if col in mapper and mapper[col] == None and col in df_part.columns:\n",
    "            df_part = df_part.drop(col)\n",
    "    \n",
    "    # rename according to supplied mapping\n",
    "    df_part = df_part.rename(mapper)\n",
    "        \n",
    "    # fill all na values for non-object/string columns\n",
    "    for col in df_part.columns:\n",
    "        if df_part[col].dtype != 'object':\n",
    "            df_part[col] = df_part[col].fillna(-1)\n",
    "    \n",
    "    return df_part\n",
    "\n",
    "# create a dict mapping existing names to intended names\n",
    "# any dict entry with `None` will be dropped\n",
    "col_map = dict.fromkeys([\n",
    "    'vendor_id', 'dropoff_datetime', 'payment_type', 'surcharge', 'mta_tax',\n",
    "    'tip_amount', 'tolls_amount', 'total_amount', 'store_and_fwd_flag'\n",
    "])\n",
    "\n",
    "# apply the `clean` function to every partition in the taxi DataFrame\n",
    "parts = [dask.delayed(clean)(part, col_map) for part in taxi_df.to_delayed()]\n",
    "taxi_df = dask_cudf.from_delayed(parts)\n",
    "\n",
    "# apply a list of filter conditions to throw out records with missing or outlier values\n",
    "query_frags = [\n",
    "    'fare_amount > 0 and fare_amount < 500',\n",
    "    'passenger_count > 0 and passenger_count < 6',\n",
    "    'pickup_longitude > -75 and pickup_longitude < -73',\n",
    "    'dropoff_longitude > -75 and dropoff_longitude < -73',\n",
    "    'pickup_latitude > 40 and pickup_latitude < 42',\n",
    "    'dropoff_latitude > 40 and dropoff_latitude < 42'\n",
    "]\n",
    "taxi_df = taxi_df.query(' and '.join(query_frags))\n",
    "\n",
    "# inspect the results of cleaning\n",
    "taxi_df.head().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Interesting Features\n",
    "\n",
    "Dask & cuDF provide standard DataFrame operations, but also let you run \"user defined functions\" on the underlying data.\n",
    "\n",
    "cuDF's [apply_rows](https://rapidsai.github.io/projects/cudf/en/0.6.0/api.html#cudf.dataframe.DataFrame.apply_rows) operation is similar to Pandas's [DataFrame.apply](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html), except that for cuDF, custom Python code is [JIT compiled by numba](https://numba.pydata.org/numba-doc/dev/cuda/kernels.html) into GPU kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>hour</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>h_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-74.005254</td>\n",
       "      <td>40.729084</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.988697</td>\n",
       "      <td>40.727127</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.411159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-73.968585</td>\n",
       "      <td>40.759171</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.964336</td>\n",
       "      <td>40.764665</td>\n",
       "      <td>4.1</td>\n",
       "      <td>10</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.707559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-73.980710</td>\n",
       "      <td>40.742390</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.987028</td>\n",
       "      <td>40.729532</td>\n",
       "      <td>6.1</td>\n",
       "      <td>23</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.524669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-73.993773</td>\n",
       "      <td>40.747329</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.991378</td>\n",
       "      <td>40.750050</td>\n",
       "      <td>5.3</td>\n",
       "      <td>23</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.363430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>-73.991475</td>\n",
       "      <td>40.749936</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.950237</td>\n",
       "      <td>40.775626</td>\n",
       "      <td>25.3</td>\n",
       "      <td>10</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.494138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_count  trip_distance  pickup_longitude  pickup_latitude  \\\n",
       "0                1            1.2        -74.005254        40.729084   \n",
       "1                1            0.4        -73.968585        40.759171   \n",
       "2                3            1.2        -73.980710        40.742390   \n",
       "3                3            0.8        -73.993773        40.747329   \n",
       "4                1            5.3        -73.991475        40.749936   \n",
       "\n",
       "   rate_code  dropoff_longitude  dropoff_latitude  fare_amount  hour  year  \\\n",
       "0          1         -73.988697         40.727127          6.1     2  2010   \n",
       "1          1         -73.964336         40.764665          4.1    10  2010   \n",
       "2          1         -73.987028         40.729532          6.1    23  2010   \n",
       "3          1         -73.991378         40.750050          5.3    23  2010   \n",
       "4          1         -73.950237         40.775626         25.3    10  2010   \n",
       "\n",
       "   month  day  day_of_week  is_weekend  h_distance  \n",
       "0     11   29          5.0         1.0    1.411159  \n",
       "1     11   28          4.0         1.0    0.707559  \n",
       "2     11   28          4.0         1.0    1.524669  \n",
       "3     11   28          4.0         1.0    0.363430  \n",
       "4     11   28          4.0         1.0    4.494138  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import cudf\n",
    "\n",
    "#Numba Kernel to calculate Haversine distance\n",
    "@numba.cuda.jit\n",
    "def haversine_kernel(lat1, lon1, lat2, lon2, outputCol):\n",
    "    iRow = numba.cuda.grid(1)\n",
    "    p = 0.017453292519943295 # Pi/180\n",
    "    if iRow < outputCol.size:\n",
    "        a = 0.5 - math.cos((lat2[iRow] - lat1[iRow]) * p)/2 + math.cos(lat1[iRow] * p) * \\\n",
    "            math.cos(lat2[iRow] * p) * (1 - math.cos((lon2[iRow] - lon1[iRow]) * p)) / 2                                 \n",
    "        outputCol[iRow] = 12734 * math.asin(math.sqrt(a))\n",
    "\n",
    "#ToDo\n",
    "# use rmm allocation from outside the kernel\n",
    "# explain ability to use numba kernels, link to examples\n",
    "# but still use apply_rows directly nicer API\n",
    "# use keith's example\n",
    "def haversine_distance(gdf):\n",
    "    nRows = gdf.shape[0]\n",
    "    blockSize = 128\n",
    "    blockCount = nRows // blockSize + 1\n",
    "    lat1_arr = gdf['pickup_latitude'].to_gpu_array()\n",
    "    lon1_arr = gdf['pickup_longitude'].to_gpu_array()\n",
    "    lat2_arr = gdf['dropoff_latitude'].to_gpu_array()\n",
    "    lon2_arr = gdf['dropoff_longitude'].to_gpu_array()\n",
    "                        \n",
    "    # allocate device memory for the result\n",
    "    outputCol = cudf.rmm.device_array ( shape=(nRows), dtype=lat1_arr.dtype.name)\n",
    "    \n",
    "    haversine_kernel[(blockCount),(blockSize)](lat1_arr, lon1_arr, lat2_arr, lon2_arr, outputCol)\n",
    "    gdf.add_column(name='h_distance', data = outputCol)\n",
    "    return gdf\n",
    "\n",
    "#Numba Kernel to calculate day of the week from Date\n",
    "@numba.cuda.jit\n",
    "def day_of_the_week_kernel(output ,year, month, day):\n",
    "    iRow = numba.cuda.grid(1)\n",
    "    if iRow < output.size:\n",
    "        year[iRow] -= month[iRow] < 3\n",
    "        month[iRow] = (month[iRow] + 9)%12 + 1\n",
    "        output[iRow] = (year[iRow] + int(year[iRow]/4) - int(year[iRow]/100) + int(year[iRow]/400) + math.floor(2.6*month[iRow] - 0.2) + day[iRow] -1) % 7\n",
    "\n",
    "#ToDo:\n",
    "#use rmm instead of cuda.device_array\n",
    "# replace day of week with apply_rows kernel\n",
    "def day_of_week(gdf):\n",
    "    nRows = gdf.shape[0]\n",
    "    blockSize = 128\n",
    "    blockCount = nRows // blockSize + 1\n",
    "    year_arr = gdf['year'].to_gpu_array()\n",
    "    month_arr = gdf['month'].to_gpu_array()\n",
    "    day_arr = gdf['day'].to_gpu_array()\n",
    "    outputCol = cudf.rmm.device_array ( shape=(nRows), dtype=day_arr.dtype.name)\n",
    "    \n",
    "    day_of_the_week_kernel[(blockCount),(blockSize)](outputCol, year_arr, month_arr, day_arr)\n",
    "    gdf.add_column(name='day_of_week', data = outputCol)\n",
    "    gdf['day_of_week'] = gdf['day_of_week'].astype('float32')\n",
    "    return gdf\n",
    "\n",
    "def add_features(df):\n",
    "    df['hour'] = df['pickup_datetime'].dt.hour\n",
    "    df['year'] = df['pickup_datetime'].dt.year\n",
    "    df['month'] = df['pickup_datetime'].dt.month\n",
    "    df['day'] = df['pickup_datetime'].dt.day\n",
    "    \n",
    "    df = df.drop('pickup_datetime')\n",
    "    \n",
    "    df = day_of_week(df)\n",
    "    df['is_weekend'] = (df['day_of_week']/4).floor()\n",
    "    df = haversine_distance(df)\n",
    "    return df\n",
    "\n",
    "# Add features\n",
    "parts = [dask.delayed(add_features)(part) for part in taxi_df.to_delayed()]\n",
    "taxi_df = dask_cudf.from_delayed(parts)\n",
    "\n",
    "taxi_df.head().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick a Training Set\n",
    "\n",
    "We'll use a query expression to identify the `year` & `month` values to use to divide the data into roughly 75% for training, and 25% for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: use multi-column groupby to compute a more meaningful train/test split boundary\n",
    "# note you could also use taxi_df.query('day < 25') if you prefer that syntax\n",
    "X_train = taxi_df[taxi_df['day'] < 25]\n",
    "\n",
    "# create a Y_train ddf with just the target variable\n",
    "Y_train = X_train[['fare_amount']]\n",
    "\n",
    "# drop the target variable from the training ddf\n",
    "X_train = X_train[X_train.columns.difference(['fare_amount'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134,637,456\n"
     ]
    }
   ],
   "source": [
    "# display how many records will be used in training\n",
    "def pretty(val):\n",
    "    print(\"{:,}\".format(val))\n",
    "\n",
    "pretty(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the XGBoost Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.75 s, sys: 92 ms, total: 2.84 s\n",
      "Wall time: 2min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import dask_xgboost as dxgb_gpu\n",
    "\n",
    "params = {\n",
    " 'learning_rate': 0.05,\n",
    "  'max_depth': 8,\n",
    "  'objective': 'reg:linear',\n",
    "  'subsample': 0.8,\n",
    "  'gamma': 1,\n",
    "  'silent': True,\n",
    "  'verbose_eval': True,\n",
    "  'tree_method':'gpu_hist',\n",
    "  'n_gpus': 1\n",
    "}\n",
    "\n",
    "bst = dxgb_gpu.train(client, params, X_train, Y_train, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Good is Our Model?\n",
    "\n",
    "Now that we have a trained model, we need to test it with the 25% of records we held out.\n",
    "\n",
    "Based on the filtering conditions applied to this dataset, many of the DataFrame partitions will wind up having 0 rows.\n",
    "\n",
    "This is a problem for XGBoost which doesn't know what to do with 0 length arrays. We'll apply a bit of Dask logic to check for and drop partitions without any rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = taxi_df.query('day >= 25')\n",
    "\n",
    "# in this dataset\n",
    "lengths = X_test.map_partitions(len).compute()\n",
    "nonempty = [length > 0 for length in lengths]\n",
    "\n",
    "X_test = X_test.partitions[nonempty]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Y_test with just the fare amount\n",
    "Y_test = X_test[['fare_amount']]\n",
    "\n",
    "# Drop the fare amount from X_test\n",
    "X_test = X_test[X_test.columns.difference(['fare_amount'])]\n",
    "\n",
    "# generate predictions on the test set\n",
    "Y_test['prediction'] = dxgb_gpu.predict(client, bst, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>prediction</th>\n",
       "      <th>squared_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.1</td>\n",
       "      <td>6.006429</td>\n",
       "      <td>0.008756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.1</td>\n",
       "      <td>4.408784</td>\n",
       "      <td>0.095348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.1</td>\n",
       "      <td>6.053908</td>\n",
       "      <td>0.002124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.3</td>\n",
       "      <td>5.076191</td>\n",
       "      <td>0.050090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.3</td>\n",
       "      <td>16.606407</td>\n",
       "      <td>75.578556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount  prediction  squared_error\n",
       "0          6.1    6.006429       0.008756\n",
       "1          4.1    4.408784       0.095348\n",
       "2          6.1    6.053908       0.002124\n",
       "3          5.3    5.076191       0.050090\n",
       "4         25.3   16.606407      75.578556"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test['squared_error'] = (Y_test['prediction'] - Y_test['fare_amount'])**2\n",
    "\n",
    "# inspect the results to make sure our calculation looks right\n",
    "Y_test.head().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.010007212284223"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the actual RMSE over the full test set\n",
    "math.sqrt(Y_test.squared_error.mean().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaways\n",
    "\n",
    "We just demonstrated how to use GPU DataFrames to scale ETL style operations out to multiple GPUs on multiple nodes.\n",
    "\n",
    "We also showed how to pass prepared data directly to XGBoost without having the data ever leave GPU memory. As a result, we can run end to end data processing _and_ model training faster, using less hardware than with a CPU based solution.\n",
    "\n",
    "What now?\n",
    "\n",
    "[Check out RAPIDS on GitHub](https://github.com/rapidsai) and follow the development, or pitch in by reporting issues, making pull requests or even just requesting the features your workflows need. We look forward to hearing from you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    vendor_name,Trip_Pickup_DateTime,Trip_Dropoff_...\n",
       "0    vendor_id,pickup_datetime,dropoff_datetime,pas...\n",
       "0    vendor_id, pickup_datetime, dropoff_datetime, ...\n",
       "0    VendorID,tpep_pickup_datetime,tpep_dropoff_dat...\n",
       "0    VendorID,tpep_pickup_datetime,tpep_dropoff_dat...\n",
       "0    VendorID,tpep_pickup_datetime,tpep_dropoff_dat...\n",
       "Name: line, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# generate list of all files\n",
    "base_dir = '/data/nyc_taxi/raw/'\n",
    "files = []\n",
    "for year in range(2009, 2019):\n",
    "    for fn in os.listdir(base_dir+str(year)):\n",
    "        if 'yellow' in fn:\n",
    "            files.append(base_dir+str(year)+'/'+fn)\n",
    "\n",
    "# get list of headers\n",
    "def get_columns(fn):\n",
    "    df = pd.DataFrame()\n",
    "    with open(fn, 'r') as fp:\n",
    "        df['year'] = [fn.split('-')[-2].split('_')[-1]]\n",
    "        df['month'] = [fn.split('-')[-1].split('.')[0]]\n",
    "        df['line'] = [fp.readline()]\n",
    "    return df\n",
    "\n",
    "parts = [dask.delayed(get_columns)(fn) for fn in files]\n",
    "res = dask.dataframe.from_delayed(parts)\n",
    "res.repartition(npartitions=1).compute().line.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return columns in df2 but not df1\n",
    "def column_delta(df1, df2):\n",
    "    return list(set(df2.columns.map(str.lower)) - set(df1.columns.map(str.lower)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# years >= 2015 data has different column names\n",
    "# remap to match existing schema\n",
    "newer_df = dask_cudf.read_csv('/data/nyc-taxi/2015/yellow_tripdata_2015-1*')\n",
    "\n",
    "# data for 2015+ has more columns\n",
    "# assume we should drop them\n",
    "for col in column_delta(taxi_df, newer_df):\n",
    "    col_map[col] = None\n",
    "\n",
    "#ratecodeid and tpep_pickup_datetime map to columns we had in years < 2014\n",
    "col_map['ratecodeid'] = 'rate_code'\n",
    "col_map['tpep_pickup_datetime'] = 'pickup_datetime'\n",
    "\n",
    "parts = [dask.delayed(clean_data)(part, col_map) for part in newer_df.to_delayed()]\n",
    "newer_df = dask_cudf.from_delayed(parts)\n",
    "\n",
    "taxi_df = taxi_df.append(newer_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}