{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting NYC Taxi Fares with RAPIDS\n",
    "\n",
    "[RAPIDS](https://rapids.ai/) is a suite of GPU accelerated data science libraries with APIs that should be familiar to uses of Pandas, Dask, and Scikitlearn.\n",
    "\n",
    "This notebook focuses on showing how to use cuDF with Dask & XGBoost to scale GPU DataFrame ETL-style operations & model training out to multiple GPUs on mutliple nodes as part of Google Cloud Dataproc.\n",
    "\n",
    "Anaconda has graciously made some of the NYC Taxi dataset available in [a public Google Cloud Storage bucket](https://console.cloud.google.com/storage/browser/anaconda-public-data/nyc-taxi/csv/). We'll use our Dataproc Cluster of GPUs to process it and train a model that predicts the fare amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://test-m:8786\n",
       "  <li><b>Dashboard: </b><a href='http://test-m:8787/status' target='_blank'>http://test-m:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>12</li>\n",
       "  <li><b>Cores: </b>12</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.142.0.2:8786' processes=11 cores=11>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numba, xgboost, socket\n",
    "\n",
    "import dask, dask_cudf\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.delayed import delayed\n",
    "from dask.distributed import Client, wait\n",
    "\n",
    "# connect to the Dask cluster that Dataproc stood up\n",
    "client = Client(socket.gethostname()+':8786')\n",
    "# forces workers to restart. useful to ensure GPU memory is clear\n",
    "client.restart()\n",
    "\n",
    "# attempt to limit work-stealing as much as possible\n",
    "dask.config.set({'distributed.scheduler.work-stealing': False})\n",
    "dask.config.get('distributed.scheduler.work-stealing')\n",
    "dask.config.set({'distributed.scheduler.bandwidth': 1})\n",
    "dask.config.get('distributed.scheduler.bandwidth')\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting the Data\n",
    "\n",
    "Now that we have a cluster of GPU workers, we'll use [dask-cudf](https://github.com/rapidsai/dask-cudf/) to load and parse a bunch of CSV files into a distributed DataFrame.\n",
    "\n",
    "First we'll tell Dask to have all workers use `gsutil cp` to copy data from the GCS bucket to local disk. This is significantly faster than having Dask read from the bucket directly into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask-cuda-worker creates one worker per GPU on Dataproc worker instances\n",
    "# Get the list of unique IP addresses\n",
    "machine_ips = []\n",
    "machines = []\n",
    "workers = list(client.scheduler_info()['workers'].keys())\n",
    "for worker in workers:\n",
    "    ip = worker.split(\":\")[1].replace(\"//\", \"\")\n",
    "    if ip not in machine_ips:\n",
    "        machine_ips.append(ip)\n",
    "        machines.append(worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b''"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def copy_files():\n",
    "    proc = subprocess.Popen(\n",
    "        \"gsutil cp -r gs://anaconda-public-data/nyc-taxi/csv/2014 .\",\n",
    "        shell=True,\n",
    "        stdout=subprocess.PIPE\n",
    "    )\n",
    "    proc.wait()\n",
    "    return proc.communicate()[0]\n",
    "\n",
    "# have each worker instance copy data for 2014 over to local disk\n",
    "#client.run(copy_files, workers=machines)\n",
    "\n",
    "# have the master copy data\n",
    "copy_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-36f38294c083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtaxi_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdask_cudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2014/yellow*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtaxi_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(self, n, npartitions, compute)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_keys__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0mpostcomputes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, dsk, keys, restrictions, loose_restrictions, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   2566\u001b[0m                     \u001b[0mshould_rejoin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2567\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2568\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2569\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2570\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, maxsize, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1820\u001b[0m                 \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m                 \u001b[0mlocal_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m                 \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1823\u001b[0m             )\n\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tornado/gen.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                         \u001b[0mexc_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tornado/gen.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    734\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mexc_info\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m                             \u001b[0myielded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m                         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m                             \u001b[0;31m# Break up a reference to itself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   1651\u001b[0m                             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCancelledError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m                             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"skip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m                         \u001b[0mbad_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    690\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/dask/compatibility.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/dask_cudf/io/csv.py\u001b[0m in \u001b[0;36m_read_csv\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_read_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mcdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mGDFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# end of file check https://github.com/rapidsai/dask-cudf/issues/103\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/cudf/io/csv.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mna_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_filter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     )\n",
      "\u001b[0;32mcudf/bindings/csv.pyx\u001b[0m in \u001b[0;36mcudf.bindings.csv.cpp_read_csv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcudf/bindings/csv.pyx\u001b[0m in \u001b[0;36mcudf.bindings.csv.cpp_read_csv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "taxi_df = dask_cudf.read_csv('2014/yellow*')\n",
    "taxi_df.head().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleanup\n",
    "\n",
    "As usual, the data needs to be massaged a bit before we can start adding features that are useful to an ML model.\n",
    "\n",
    "In this case, the taxi data for different years has different column names. We'll do a little string manipulation, column renaming and dropping to fix the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-12-13 08:17:27</td>\n",
       "      <td>2012-12-13 08:38:40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-73.964110</td>\n",
       "      <td>40.757821</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.983536</td>\n",
       "      <td>40.754967</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-12-13 08:35:37</td>\n",
       "      <td>2012-12-13 08:54:25</td>\n",
       "      <td>1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>-73.968500</td>\n",
       "      <td>40.798956</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.984140</td>\n",
       "      <td>40.759404</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-12-13 08:38:59</td>\n",
       "      <td>2012-12-13 08:43:43</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-74.006575</td>\n",
       "      <td>40.731896</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.998296</td>\n",
       "      <td>40.736337</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-12-13 08:56:37</td>\n",
       "      <td>2012-12-13 09:00:01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-73.975472</td>\n",
       "      <td>40.785340</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.971740</td>\n",
       "      <td>40.791869</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-12-13 07:43:04</td>\n",
       "      <td>2012-12-13 07:47:53</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-73.984874</td>\n",
       "      <td>40.763159</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.974123</td>\n",
       "      <td>40.759363</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pickup_datetime    dropoff_datetime  passenger_count  trip_distance  \\\n",
       "0 2012-12-13 08:17:27 2012-12-13 08:38:40                1            1.9   \n",
       "1 2012-12-13 08:35:37 2012-12-13 08:54:25                1            3.4   \n",
       "2 2012-12-13 08:38:59 2012-12-13 08:43:43                1            0.7   \n",
       "3 2012-12-13 08:56:37 2012-12-13 09:00:01                1            0.6   \n",
       "4 2012-12-13 07:43:04 2012-12-13 07:47:53                1            0.7   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  rate_code  dropoff_longitude  \\\n",
       "0        -73.964110        40.757821          1         -73.983536   \n",
       "1        -73.968500        40.798956          1         -73.984140   \n",
       "2        -74.006575        40.731896          1         -73.998296   \n",
       "3        -73.975472        40.785340          1         -73.971740   \n",
       "4        -73.984874        40.763159          1         -73.974123   \n",
       "\n",
       "   dropoff_latitude  fare_amount  \n",
       "0         40.754967         14.5  \n",
       "1         40.759404         15.0  \n",
       "2         40.736337          5.5  \n",
       "3         40.791869          4.5  \n",
       "4         40.759363          5.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# helper function which takes a DataFrame partition\n",
    "def clean(df_part, mapper):    \n",
    "    # some col-names include pre-pended space.. remove them\n",
    "    tmp = {col:col.strip().lower() for col in list(df_part.columns)}\n",
    "    df_part = df_part.rename(tmp)\n",
    "    \n",
    "    # drop any column without a supplied replacement name\n",
    "    for col in mapper:\n",
    "        if col in mapper and mapper[col] == None and col in df_part.columns:\n",
    "            df_part = df_part.drop(col)\n",
    "    \n",
    "    # rename according to supplied mapping\n",
    "    df_part = df_part.rename(mapper)\n",
    "        \n",
    "    # fill all na values for non-object/string columns\n",
    "    for col in df_part.columns:\n",
    "        if df_part[col].dtype != 'object':\n",
    "            df_part[col] = df_part[col].fillna(-1)\n",
    "    \n",
    "    return df_part\n",
    "\n",
    "# create a dict mapping existing names to intended names\n",
    "# any dict entry with `None` will be dropped\n",
    "col_map = dict.fromkeys([\n",
    "    'vendor_id', 'vendorid', 'payment_type', 'surcharge', 'mta_tax',\n",
    "    'tip_amount', 'tolls_amount', 'total_amount', 'store_and_fwd_flag', 'pulocationid',\n",
    "    'dolocationid'\n",
    "])\n",
    "col_map['tpep_pickup_datetime'] = 'pickup_datetime'\n",
    "col_map['tpep_dropoff_datetime'] = 'dropoff_datetime'\n",
    "col_map['ratecodeid'] = 'rate_code'\n",
    "\n",
    "# apply the `clean` function to every partition in the taxi DataFrame\n",
    "parts = [dask.delayed(clean)(part, col_map) for part in taxi_df.to_delayed()]\n",
    "taxi_df = dask_cudf.from_delayed(parts)\n",
    "\n",
    "# apply a list of filter conditions to throw out records with missing or outlier values\n",
    "query_frags = [\n",
    "    'fare_amount > 0 and fare_amount < 500',\n",
    "    'passenger_count > 0 and passenger_count < 6',\n",
    "    'pickup_longitude > -75 and pickup_longitude < -73',\n",
    "    'dropoff_longitude > -75 and dropoff_longitude < -73',\n",
    "    'pickup_latitude > 40 and pickup_latitude < 42',\n",
    "    'dropoff_latitude > 40 and dropoff_latitude < 42'\n",
    "]\n",
    "taxi_df = taxi_df.query(' and '.join(query_frags))\n",
    "\n",
    "# inspect the results of cleaning\n",
    "taxi_df.head().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Interesting Features\n",
    "\n",
    "Dask & cuDF provide standard DataFrame operations, but also let you run \"user defined functions\" on the underlying data.\n",
    "\n",
    "cuDF's [apply_rows](https://rapidsai.github.io/projects/cudf/en/0.6.0/api.html#cudf.dataframe.DataFrame.apply_rows) operation is similar to Pandas's [DataFrame.apply](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html), except that for cuDF, custom Python code is [JIT compiled by numba](https://numba.pydata.org/numba-doc/dev/cuda/kernels.html) into GPU kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>hour</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>diff</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>h_distance</th>\n",
       "      <th>pick_lat_round</th>\n",
       "      <th>drop_lat_round</th>\n",
       "      <th>pick_long_round</th>\n",
       "      <th>drop_long_round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>14.5</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>1273000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.665683</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>-73</td>\n",
       "      <td>-73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>1128000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.588028</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>-73</td>\n",
       "      <td>-73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>284000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.854130</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>-74</td>\n",
       "      <td>-73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>204000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.790566</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>-73</td>\n",
       "      <td>-73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>289000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998404</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>-73</td>\n",
       "      <td>-73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_count  trip_distance  rate_code  fare_amount  hour  year  month  \\\n",
       "0                1            1.9          1         14.5     8  2012     10   \n",
       "1                1            3.4          1         15.0     8  2012     10   \n",
       "2                1            0.7          1          5.5     8  2012     10   \n",
       "3                1            0.6          1          4.5     8  2012     10   \n",
       "4                1            0.7          1          5.0     7  2012     10   \n",
       "\n",
       "   day     diff  day_of_week  is_weekend  h_distance  pick_lat_round  \\\n",
       "0   13  1273000          3.0         0.0    1.665683              41   \n",
       "1   13  1128000          3.0         0.0    4.588028              41   \n",
       "2   13   284000          3.0         0.0    0.854130              41   \n",
       "3   13   204000          3.0         0.0    0.790566              41   \n",
       "4   13   289000          3.0         0.0    0.998404              41   \n",
       "\n",
       "   drop_lat_round  pick_long_round  drop_long_round  \n",
       "0              41              -73              -73  \n",
       "1              41              -73              -73  \n",
       "2              41              -74              -73  \n",
       "3              41              -73              -73  \n",
       "4              41              -73              -73  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import cudf\n",
    "\n",
    "#Numba Kernel to calculate Haversine distance\n",
    "@numba.cuda.jit\n",
    "def haversine_kernel(lat1, lon1, lat2, lon2, outputCol):\n",
    "    iRow = numba.cuda.grid(1)\n",
    "    p = 0.017453292519943295 # Pi/180\n",
    "    if iRow < outputCol.size:\n",
    "        a = 0.5 - math.cos((lat2[iRow] - lat1[iRow]) * p)/2 + math.cos(lat1[iRow] * p) * \\\n",
    "            math.cos(lat2[iRow] * p) * (1 - math.cos((lon2[iRow] - lon1[iRow]) * p)) / 2                                 \n",
    "        outputCol[iRow] = 12734 * math.asin(math.sqrt(a))\n",
    "\n",
    "def haversine_distance(gdf):\n",
    "    nRows = gdf.shape[0]\n",
    "    blockSize = 128\n",
    "    blockCount = nRows // blockSize + 1\n",
    "    lat1_arr = gdf['pickup_latitude'].to_gpu_array()\n",
    "    lon1_arr = gdf['pickup_longitude'].to_gpu_array()\n",
    "    lat2_arr = gdf['dropoff_latitude'].to_gpu_array()\n",
    "    lon2_arr = gdf['dropoff_longitude'].to_gpu_array()\n",
    "                        \n",
    "    # allocate device memory for the result\n",
    "    outputCol = cudf.rmm.device_array ( shape=(nRows), dtype=lat1_arr.dtype.name)\n",
    "    \n",
    "    haversine_kernel[(blockCount),(blockSize)](lat1_arr, lon1_arr, lat2_arr, lon2_arr, outputCol)\n",
    "    gdf.add_column(name='h_distance', data = outputCol)\n",
    "    return gdf\n",
    "\n",
    "#Numba Kernel to calculate day of the week from Date\n",
    "@numba.cuda.jit\n",
    "def day_of_the_week_kernel(output ,year, month, day):\n",
    "    iRow = numba.cuda.grid(1)\n",
    "    if iRow < output.size:\n",
    "        year[iRow] -= month[iRow] < 3\n",
    "        month[iRow] = (month[iRow] + 9)%12 + 1\n",
    "        output[iRow] = (year[iRow] + int(year[iRow]/4) - int(year[iRow]/100) + int(year[iRow]/400) + math.floor(2.6*month[iRow] - 0.2) + day[iRow] -1) % 7\n",
    "\n",
    "@numba.cuda.jit\n",
    "def round_kernel(lat1, outputCol):\n",
    "    iRow = numba.cuda.grid(1)\n",
    "    if iRow < outputCol.size:\n",
    "        a = math.ceil(lat1[iRow])\n",
    "        outputCol[iRow] = a\n",
    "        \n",
    "def lat_rounder(gdf, lat, name):\n",
    "    nRows = gdf.shape[0]\n",
    "    blockSize = 128\n",
    "    blockCount = nRows // blockSize + 1\n",
    "    lat1_arr = gdf[lat].to_gpu_array()\n",
    "    \n",
    "    outputCol = cudf.rmm.device_array ( shape=(nRows), dtype='int32')\n",
    "    \n",
    "    round_kernel[(blockCount, blockSize)](lat1_arr, outputCol)\n",
    "    gdf.add_column(name=name, data=outputCol)\n",
    "    return gdf\n",
    "        \n",
    "        \n",
    "def day_of_week(gdf):\n",
    "    nRows = gdf.shape[0]\n",
    "    blockSize = 128\n",
    "    blockCount = nRows // blockSize + 1\n",
    "    year_arr = gdf['year'].to_gpu_array()\n",
    "    month_arr = gdf['month'].to_gpu_array()\n",
    "    day_arr = gdf['day'].to_gpu_array()\n",
    "    outputCol = cudf.rmm.device_array ( shape=(nRows), dtype=day_arr.dtype.name)\n",
    "    \n",
    "    day_of_the_week_kernel[(blockCount),(blockSize)](outputCol, year_arr, month_arr, day_arr)\n",
    "    gdf.add_column(name='day_of_week', data = outputCol)\n",
    "    gdf['day_of_week'] = gdf['day_of_week'].astype('float32')\n",
    "    return gdf\n",
    "\n",
    "def add_features(df):\n",
    "    df['hour'] = df['pickup_datetime'].dt.hour\n",
    "    df['year'] = df['pickup_datetime'].dt.year\n",
    "    df['month'] = df['pickup_datetime'].dt.month\n",
    "    df['day'] = df['pickup_datetime'].dt.day\n",
    "    df['diff'] = df['dropoff_datetime'].astype('int64') - df['pickup_datetime'].astype('int64')\n",
    "    \n",
    "    df = df.drop('pickup_datetime')\n",
    "    df = df.drop('dropoff_datetime')\n",
    "    \n",
    "    df = day_of_week(df)\n",
    "    df['is_weekend'] = (df['day_of_week']/4).floor()\n",
    "    df = haversine_distance(df)\n",
    "    df = lat_rounder(df, 'pickup_latitude','pick_lat_round')\n",
    "    df = lat_rounder(df, 'dropoff_latitude','drop_lat_round')\n",
    "    df = lat_rounder(df, 'pickup_longitude','pick_long_round')\n",
    "    df = lat_rounder(df, 'dropoff_longitude','drop_long_round')\n",
    "    \n",
    "    df = df.drop('pickup_latitude')\n",
    "    df = df.drop('dropoff_latitude')\n",
    "    df = df.drop('pickup_longitude')\n",
    "    df = df.drop('dropoff_longitude')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Add features\n",
    "parts = [dask.delayed(add_features)(part) for part in taxi_df.to_delayed()]\n",
    "taxi_df = dask_cudf.from_delayed(parts)\n",
    "\n",
    "taxi_df.head().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick a Training Set\n",
    "\n",
    "Let's imagine you're making a trip to New York on the 25th and want to build a model to predict what fare prices will be like the last few days of the month based on the first part of the month. We'll use a query expression to identify the `day` of the month to use to divide the data into train and test sets.\n",
    "\n",
    "The wall-time below represents how long it takes your GPU cluster to run the ETL portion of the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoneAndNotDoneFutures(done={<Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 15)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 12)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 5)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 15)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 8)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 18)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 14)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 19)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 7)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 8)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 5)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 17)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 17)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 10)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 0)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 12)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 14)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 23)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 16)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 21)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 20)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 6)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 11)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 10)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 18)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 2)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 7)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 4)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 19)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 6)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 20)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 21)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 22)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 1)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 23)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 9)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 1)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 13)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 2)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 3)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 9)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 13)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 22)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 0)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 11)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 16)>, <Future: status: finished, type: DataFrame, key: ('getitem-5e3e1945a4f1058deca7894afdd1fced', 3)>, <Future: status: finished, type: DataFrame, key: ('getitem-f4f254366f8a8df1f7d9fe88baab4f78', 4)>}, not_done=set())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# note you could also use taxi_df.query('day < 25') if you prefer that syntax\n",
    "X_train = taxi_df[taxi_df['day'] < 25]\n",
    "\n",
    "# create a Y_train ddf with just the target variable\n",
    "Y_train = X_train[['fare_amount']]\n",
    "\n",
    "# drop the target variable from the training ddf\n",
    "X_train = X_train[X_train.columns.difference(['fare_amount'])]\n",
    "\n",
    "# force compute these DataFrames and persist them in GPU memory\n",
    "X_train = X_train.persist()\n",
    "Y_train = Y_train.persist()\n",
    "\n",
    "# this wont return until all data is in GPU memory\n",
    "wait([X_train, Y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263,428,853\n"
     ]
    }
   ],
   "source": [
    "# display how many records will be used in training\n",
    "def pretty(val):\n",
    "    print(\"{:,}\".format(val))\n",
    "\n",
    "pretty(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the XGBoost Regression Model\n",
    "\n",
    "The wall time output below indicates how long it took your GPU cluster to train an XGBoost model over the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 144 ms, sys: 40 ms, total: 184 ms\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import dask_xgboost as dxgb_gpu\n",
    "\n",
    "params = {\n",
    " 'learning_rate': 0.3,\n",
    "  'max_depth': 8,\n",
    "  'objective': 'reg:squarederror', #gpu:reg deprecated\n",
    "  'subsample': 0.6,\n",
    "  'gamma': 1,\n",
    "  'silent': True,\n",
    "  'verbose_eval': True,\n",
    "  'tree_method':'gpu_hist',\n",
    "  'n_gpus': 1\n",
    "}\n",
    "\n",
    "bst = dxgb_gpu.train(client, params, X_train, Y_train, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Good is Our Model?\n",
    "\n",
    "Now that we have a trained model, we need to test it with the 25% of records we held out.\n",
    "\n",
    "Based on the filtering conditions applied to this dataset, many of the DataFrame partitions will wind up having 0 rows.\n",
    "\n",
    "This is a problem for XGBoost which doesn't know what to do with 0 length arrays. We'll apply a bit of Dask logic to check for and drop partitions without any rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = taxi_df.query('day >= 25')\n",
    "\n",
    "# in this dataset\n",
    "lengths = X_test.map_partitions(len).compute()\n",
    "nonempty = [length > 0 for length in lengths]\n",
    "\n",
    "X_test = X_test.partitions[nonempty].persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Y_test with just the fare amount\n",
    "Y_test = X_test[['fare_amount']]\n",
    "\n",
    "# Drop the fare amount from X_test\n",
    "X_test = X_test[X_test.columns.difference(['fare_amount'])]\n",
    "\n",
    "# generate predictions on the test set\n",
    "Y_test['prediction'] = dxgb_gpu.predict(client, bst, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>prediction</th>\n",
       "      <th>squared_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>15.0</td>\n",
       "      <td>14.558580</td>\n",
       "      <td>0.194851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.5</td>\n",
       "      <td>7.428008</td>\n",
       "      <td>0.005183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.236113</td>\n",
       "      <td>0.055749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>8.5</td>\n",
       "      <td>8.829840</td>\n",
       "      <td>0.108794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.096241</td>\n",
       "      <td>0.009262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fare_amount  prediction  squared_error\n",
       "123         15.0   14.558580       0.194851\n",
       "125          7.5    7.428008       0.005183\n",
       "126          8.0    8.236113       0.055749\n",
       "127          8.5    8.829840       0.108794\n",
       "128          7.0    7.096241       0.009262"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test['squared_error'] = (Y_test['prediction'] - Y_test['fare_amount'])**2\n",
    "\n",
    "# inspect the results to make sure our calculation looks right\n",
    "Y_test.head().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7131995443517858"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the actual RMSE over the full test set\n",
    "math.sqrt(Y_test.squared_error.mean().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaways\n",
    "\n",
    "We just demonstrated how to use GPU DataFrames to scale ETL style operations out to multiple GPUs on multiple nodes.\n",
    "\n",
    "We also showed how to pass prepared data directly to XGBoost without having the data ever leave GPU memory. As a result, we can run end to end data processing _and_ model training faster, using less hardware than with a CPU based solution.\n",
    "\n",
    "What now?\n",
    "\n",
    "[Check out RAPIDS on GitHub](https://github.com/rapidsai) and follow the development, or pitch in by reporting issues, making pull requests or even just requesting the features your workflows need. We look forward to hearing from you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    vendor_name,Trip_Pickup_DateTime,Trip_Dropoff_...\n",
       "0    vendor_id,pickup_datetime,dropoff_datetime,pas...\n",
       "0    vendor_id, pickup_datetime, dropoff_datetime, ...\n",
       "0    VendorID,tpep_pickup_datetime,tpep_dropoff_dat...\n",
       "0    VendorID,tpep_pickup_datetime,tpep_dropoff_dat...\n",
       "0    VendorID,tpep_pickup_datetime,tpep_dropoff_dat...\n",
       "Name: line, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# generate list of all files\n",
    "base_dir = '/data/nyc_taxi/raw/'\n",
    "files = []\n",
    "for year in range(2009, 2019):\n",
    "    for fn in os.listdir(base_dir+str(year)):\n",
    "        if 'yellow' in fn:\n",
    "            files.append(base_dir+str(year)+'/'+fn)\n",
    "\n",
    "# get list of headers\n",
    "def get_columns(fn):\n",
    "    df = pd.DataFrame()\n",
    "    with open(fn, 'r') as fp:\n",
    "        df['year'] = [fn.split('-')[-2].split('_')[-1]]\n",
    "        df['month'] = [fn.split('-')[-1].split('.')[0]]\n",
    "        df['line'] = [fp.readline()]\n",
    "    return df\n",
    "\n",
    "parts = [dask.delayed(get_columns)(fn) for fn in files]\n",
    "res = dask.dataframe.from_delayed(parts)\n",
    "res.repartition(npartitions=1).compute().line.drop_duplicates()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
